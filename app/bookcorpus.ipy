"""
This script does some preliminary exploration of the amount of occurrences present in the
filtered bookcorpus. The conclusion is that 74% of the selected words have at least 786 
(d_BERT) occurrences, 92% have at least 100 occurrences only 3 words have less than 
10 occurrences.
"""

# %%
import datasets

ds = datasets.load_from_disk("../data/bookcorpus-filtered")

# %%

with open("../data/selected-words.csv", "r") as file:
    next(file)
    words = [
        " " + word + " "
        for row in file.read().split("\n")
        for word in row.split(",")
        if word
    ]
import collections as c

wordcount = c.defaultdict(int)

from tqdm import tqdm

for line in tqdm(ds):
    for word in words:
        if word in line["text"]:
            wordcount[word] += 1
# %%
import matplotlib.pyplot as plt

names = list(wordcount.keys())
values = list(wordcount.values())
ticks = list(range(len(names)))

# %%

plt.figure(figsize=(30, 6))
plt.bar(ticks, values)
plt.hlines([768, 100, 10], 0, len(ticks), ["red", "red", "red"], "dashed")
plt.xticks(range(len(names)), labels=names, rotation=-90)
plt.yscale("log")
plt.show()

# %%

print(
    f"{100*len([val for val in values if val>=768])/len(values):.2f}%"
)  # 74% of words have at least 768 occurrences
print(
    f"{100*len([val for val in values if val>=100])/len(values):.2f}%"
)  # 92% of words have at least 100 occurrences
# %%
