# %%
import torch
from torch import Tensor

import wsd.data.coarsewsd20 as cwsd
from wsd.data.entry import transpose_entries
from wsd.util.batch import batched
from wsd.vectorise.bert import BertVectoriser

# %%

data = cwsd.load_dataset(cwsd.Variant.REGULAR, root="../data/CoarseWSD-20")[
    "seal"
].train
entries = transpose_entries(data)

# Third-party imports
# %%
import matplotlib.pyplot as plt
import numpy as np
import umap

# %% Load data
word = "bow"
split = "train"

embeddings_tr = np.load(f"../out/vectorised/bert-base-uncased/{word}.train.npy")
entries_tr = transpose_entries(
    cwsd.load_dataset(cwsd.Variant.REGULAR, root="../data/CoarseWSD-20")[
        word
    ].get_data_split("train")
)

embeddings_te = np.load(f"../out/vectorised/bert-base-uncased/{word}.test.npy")
entries_te = transpose_entries(
    cwsd.load_dataset(cwsd.Variant.REGULAR, root="../data/CoarseWSD-20")[
        word
    ].get_data_split("test")
)
entries = cwsd.load_dataset(cwsd.Variant.REGULAR, root="../data/CoarseWSD-20")[
    word
].vertical()
umap_emb = umap.UMAP().fit_transform(np.concatenate((embeddings_tr, embeddings_te)))

# %%

plt.scatter(
    umap_emb[:, 0],
    umap_emb[:, 1],
    c=[["red", "blue", "green", "purple"][x] for x in entries.target_class_ids],
)
plt.gca().set_aspect("equal", "datalim")
plt.title("UMAP projection of CWSD sentences 'chair'", fontsize=24)
# Third-party imports

# Third-party imports

# %%
